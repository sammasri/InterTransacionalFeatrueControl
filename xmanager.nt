{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp;<b>Setups and Drive</b>{ form-width: \"2%\" }\n",
    "#@markdown\n",
    "\n",
    "Drive = False #@param {type:\"boolean\"}\n",
    "\n",
    "import os, re, pytz, glob, hashlib, json, sys\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from google.colab import drive\n",
    " \n",
    "if Drive and not os.path.exists('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "# Assuming these helper functions/regexes exist in your environment\n",
    "linuxfilepath_re = re.compile(r'\\/[\\w\\-\\.\\/]+|\\\"[\\w\\-\\.\\/\\s]+\\\"')\n",
    "zipfile_re = re.compile(r'\\.zip$', re.IGNORECASE)\n",
    "\n",
    "class PathItem:\n",
    "    def __init__(self, abs_p, rel_p, ancestor, size=None):\n",
    "        self.absolute_path = abs_p\n",
    "        self.relative_path = rel_p\n",
    "        self.ancestor = ancestor\n",
    "        self.size = size\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {\n",
    "            \"absolute_path\": self.absolute_path,\n",
    "            \"relative_path\": self.relative_path,\n",
    "            \"ancestor\": self.ancestor,\n",
    "            \"size\": self.size\n",
    "        }\n",
    "\n",
    "    @classmethod\n",
    "    def from_dict(cls, data):\n",
    "        return cls(\n",
    "            data[\"absolute_path\"], \n",
    "            data[\"relative_path\"], \n",
    "            data[\"ancestor\"],\n",
    "            data.get(\"size\") # Handle backward compatibility or missing size\n",
    "        )\n",
    "    \n",
    "tz = pytz.timezone('Turkey')\n",
    "size_limit = 20000\n",
    "units = {\"B\": 1, \"KB\": 1024, \"MB\": 1024**2, \"GB\": 1024**3, \"TB\": 1024**4}\n",
    "\n",
    "zipfile_re = re.compile(r\"\\.([Zz][Ii][Pp]|[Gg][Zz]|[Rr][Aa][Rr]|7[Zz]|[Tt][Aa][Rr])$\")\n",
    "extdot_re = r\"\\.(?=\\w+$)\"\n",
    "file_re = r\"^.*\\.[A-Z,a-z,0-9]+$\"\n",
    "url_re = r\"((http[s]?):\\/\\/)?([^:\\/\\s]+)((\\/\\w+\\/)*\\/)([\\w\\-\\.]+[^#?\\s]+)(.*)?(#[\\w\\-]+)?\"\n",
    "file_url_re = r\"((http[s]?):\\/\\/)?([^:\\/\\s\\\"<>(\\\\n)]+)((\\/\\w{3}\\/)*\\/)([\\w\\-\\.]+[^#?\\s\\\"<>(\\\\n)]+)([^:\\/\\s\\\"<>(\\\\n)].*)?(#[\\w\\-]+)?\"\n",
    "\n",
    "quotation_re = re.compile(r'^\\s*([\\'\"])(.*?)\\1\\s*$')\n",
    "def remove_quotes(text):\n",
    "    \"\"\"Removes matching quotes from the start and end of a string.\"\"\"\n",
    "    return quotation_re.sub(r'\\2', text)\n",
    "\n",
    "lastletters_re = re.compile(r\"\\s*[A-Za-z]{1,}\\s*\")\n",
    "digits_re = re.compile(r\"\\s*[0-9]{1,}\\s*\")\n",
    "\n",
    "def get_path_hash(path: str, size: int) -> str:\n",
    "    \"\"\"\n",
    "    Generates a deterministic hash for a file path and its size.\n",
    "    \"\"\"\n",
    "    signature = f\"{path}|{size}\".encode('utf-8')\n",
    "    return hashlib.md5(signature).hexdigest()\n",
    "\n",
    "def calculate_combined_hash(input_hashes):\n",
    "    \"\"\"\n",
    "    Calculates the combined hash for a job using XOR on input hashes.\n",
    "    Expects a list of integer hashes.\n",
    "    \"\"\"\n",
    "    job_hash_int = 0\n",
    "    for h in input_hashes:\n",
    "        job_hash_int ^= h\n",
    "    return hex(job_hash_int)[2:]\n",
    "\n",
    "def str_num(s):\n",
    "    \"\"\"\n",
    "    Parses a string size (e.g., '20 GB', '100MB') into bytes.\n",
    "    \"\"\"\n",
    "    if isinstance(s, (int, float)):\n",
    "        return int(s)\n",
    "    s = s.strip().upper()\n",
    "    # regex to separate number and unit\n",
    "    match = re.match(r\"([0-9\\.]+)\\s*([A-Z]+)?\", s)\n",
    "    if match:\n",
    "        number = float(match.group(1))\n",
    "        unit = match.group(2)\n",
    "        multiplier = units.get(unit, 1) # Default to Bytes if no unit\n",
    "        return int(number * multiplier)\n",
    "    return 0\n",
    "\n",
    "def format_split_size(size_bytes):\n",
    "    \"\"\"\n",
    "    Formats bytes into zip-compatible split size string (k, m, g).\n",
    "    \"\"\"\n",
    "    if size_bytes <= 0: return \"\"\n",
    "    \n",
    "    # Check for Giga\n",
    "    if size_bytes % (1024**3) == 0:\n",
    "        return f\"{int(size_bytes / (1024**3))}g\"\n",
    "    \n",
    "    # Check for Mega (Most common for zip splits)\n",
    "    if size_bytes % (1024**2) == 0:\n",
    "        return f\"{int(size_bytes / (1024**2))}m\"\n",
    "        \n",
    "    # Check for Kilo\n",
    "    if size_bytes % 1024 == 0:\n",
    "        return f\"{int(size_bytes / 1024)}k\"\n",
    "        \n",
    "    # Fallback: Round down to nearest Kilo (Zip generally requires multiples of k, m, g)\n",
    "    return f\"{int(size_bytes // 1024)}k\"\n",
    "\n",
    "exlessbase = lambda path: os.path.basename(os.path.splitext(path)[0])\n",
    "nowstr = lambda separete = False: datetime.now(tz).strftime(\"%y-%m-%d-%H-%M-%S\") if separete else str(round(time.time()))\n",
    "\n",
    "def RoundTo1(n) :\n",
    "    if n < 1 and (n - 0.9765625) >= 0 :\n",
    "        return 1\n",
    "    else: \n",
    "        return n\n",
    "\n",
    "ByteToGB = lambda n: RoundTo1(n/1073741824)\n",
    "ByteToMB = lambda n: RoundTo1(n/1048576)\n",
    "ByteToKB = lambda n: RoundTo1(n/1024)\n",
    "\n",
    "def data_str(byte_val):\n",
    "    size = ByteToGB(byte_val)\n",
    "    if (size >= 1):\n",
    "        return \"{:.1f} GB\".format(size)\n",
    "    size = ByteToMB(byte_val)\n",
    "    if (size >= 1):\n",
    "        return \"{:.1f} MB\".format(size)\n",
    "    size = ByteToKB(byte_val)\n",
    "    if (size >= 1):\n",
    "        return \"{:.1f} KB\".format(size)\n",
    "    return \"{:.1f} B\".format(size)\n",
    "\n",
    "def get_path_size(path):\n",
    "    \"\"\"Calculates size of file or total size of directory.\"\"\"\n",
    "    if os.path.isfile(path):\n",
    "        return os.path.getsize(path)\n",
    "    elif os.path.isdir(path):\n",
    "        total_size = 0\n",
    "        try:\n",
    "            for dirpath, _, filenames in os.walk(path):\n",
    "                for f in filenames:\n",
    "                    fp = os.path.join(dirpath, f)\n",
    "                    if not os.path.islink(fp):\n",
    "                        total_size += os.path.getsize(fp)\n",
    "        except PermissionError:\n",
    "            pass # Skip unreadable\n",
    "        return total_size\n",
    "    return 0\n",
    "\n",
    "def getwildcartpaths(path, quoted=True):\n",
    "    \"\"\"Returns a list of paths matching the wildcard pattern in the given path.\"\"\"\n",
    "    res = glob.glob(path)\n",
    "    if not quoted:\n",
    "        return res\n",
    "    for i in range(len(res)): \n",
    "        if \" \" in res[i]:\n",
    "            res[i] = f'\"{res[i]}\"'\n",
    "    return res\n",
    "\n",
    "def organize_paths(paths):\n",
    "    dirs, files = [], []\n",
    "    for p in paths:\n",
    "        if os.path.isdir(p): dirs.append(p)\n",
    "        else: files.append(p)\n",
    "    return dirs, files\n",
    "\n",
    "def zip_with_str_input(input_str, saveto: str = \"\", split = \"\", size_limit= \"\", deletefiles= False, callback = None):\n",
    "    \"\"\"\n",
    "    Parses a string input, converts it to input_items, and calls the main zip function.\n",
    "    \"\"\"\n",
    "    if not input_str:\n",
    "        print(\"No input provided.\")\n",
    "        return None\n",
    "\n",
    "    # --- Parse String Input ---\n",
    "    inputpathlist = linuxfilepath_re.findall(input_str)\n",
    "    inputpathlist = [remove_quotes(p) for p in inputpathlist]\n",
    "    \n",
    "    # Check for single path wildcard expansion\n",
    "    size_limit_val = str_num(size_limit)\n",
    "    if len(inputpathlist) == 1 and size_limit_val and inputpathlist[0].endswith(\"*\"):\n",
    "        inputpathlist = getwildcartpaths(inputpathlist[0], quoted = False)\n",
    "\n",
    "    # Filter out non-existent paths\n",
    "    inputpathlist = [p for p in inputpathlist if os.path.exists(p)]\n",
    "    \n",
    "    if not inputpathlist:\n",
    "        print(\"No valid input paths found.\")\n",
    "        return None\n",
    "\n",
    "    # --- Convert to PathItem Objects ---\n",
    "    # Separate Dirs and Files\n",
    "    dir_paths, file_paths = organize_paths(inputpathlist)\n",
    "    \n",
    "    dirs_list_obj = []\n",
    "    files_list_obj = []\n",
    "\n",
    "    # Create Directory Objects\n",
    "    for d in dir_paths:\n",
    "        abs_p = os.path.abspath(d)\n",
    "        ancestor = os.path.dirname(abs_p)\n",
    "        rel_p = os.path.basename(abs_p)\n",
    "        dirs_list_obj.append(PathItem(abs_p, rel_p, ancestor))\n",
    "\n",
    "    # Create File Objects\n",
    "    for f in file_paths:\n",
    "        abs_p = os.path.abspath(f)\n",
    "        ancestor = os.path.dirname(abs_p)\n",
    "        rel_p = os.path.basename(abs_p)\n",
    "        files_list_obj.append(PathItem(abs_p, rel_p, ancestor))\n",
    "\n",
    "    # --- Call Main Zip Function ---\n",
    "    return zip(\n",
    "        saveto=saveto,\n",
    "        split=split,\n",
    "        size_limit=size_limit,\n",
    "        deletefiles=deletefiles,\n",
    "        callback=callback,\n",
    "        input_items=(dirs_list_obj, files_list_obj)\n",
    "    )\n",
    "\n",
    "def zip(input_items, saveto: str = \"\", split = \"\", size_limit= \"\", deletefiles= False, callback = None):\n",
    "    \"\"\"\n",
    "    Main zip function working with structured input_items.\n",
    "    \"\"\"\n",
    "    saveto = saveto.strip() if saveto else \"\"\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    if not input_items or (not input_items[0] and not input_items[1]):\n",
    "        print(\"No input items provided.\")\n",
    "        return None\n",
    "\n",
    "    dirs_list_obj = input_items[0]\n",
    "    files_list_obj = input_items[1]\n",
    "    all_targets = dirs_list_obj + files_list_obj\n",
    "    \n",
    "    # --- Determine Default Filename ---\n",
    "    if len(all_targets) == 1:\n",
    "        path_for_name = all_targets[0].absolute_path\n",
    "        basename = os.path.basename(path_for_name)\n",
    "        default_savename = f\"{basename}.zip\"\n",
    "    else:\n",
    "        default_savename = f\"zipped-files-{nowstr(True)}.zip\"\n",
    "\n",
    "    # --- Process 'saveto' Logic ---\n",
    "    if saveto:\n",
    "        sch = zipfile_re.search(saveto)\n",
    "        if sch:\n",
    "            savename = saveto\n",
    "        else:\n",
    "            savename = os.path.join(saveto, default_savename)\n",
    "        \n",
    "        savedir = os.path.dirname(savename)\n",
    "        if savedir:\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "    else:\n",
    "        savename = default_savename\n",
    "\n",
    "    # Convert savename to absolute path\n",
    "    savename = os.path.abspath(savename)\n",
    "\n",
    "    print(f\"To: {savename}\")\n",
    "    \n",
    "    splitparam = f\" -s {split} \" if split else \"\"\n",
    "    command_list = []\n",
    "\n",
    "    # --- Generate Commands ---\n",
    "    \n",
    "    # Process Directories\n",
    "    for item in dirs_list_obj:\n",
    "        ancestor = item.ancestor\n",
    "        rel_path = item.relative_path\n",
    "        cmd_chunk = f'cd \"{ancestor}\" && zip -7 -r{splitparam} -qdg \"{savename}\" \"{rel_path}\"'\n",
    "        command_list.append(cmd_chunk)\n",
    "        \n",
    "    # Process Files\n",
    "    for item in files_list_obj:\n",
    "        ancestor = item.ancestor\n",
    "        rel_path = item.relative_path\n",
    "        cmd_chunk = f'cd \"{ancestor}\" && zip -7{splitparam} -qdg \"{savename}\" \"{rel_path}\"'\n",
    "        command_list.append(cmd_chunk)\n",
    "\n",
    "    # --- Combine and Execute ---\n",
    "    \n",
    "    if not command_list:\n",
    "        print(\"No commands generated.\")\n",
    "        return None\n",
    "\n",
    "    cm = \" && \".join(command_list)\n",
    "    print(f\"Command: {cm}\")\n",
    "    \n",
    "    # Mock execution \n",
    "    result = os.system(cm)\n",
    "    success = True \n",
    "    \n",
    "    # Restore original directory\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    if success:\n",
    "        return savename\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_job_parts(input_items, part_size_byte, max_overflow_byte):\n",
    "    \"\"\"\n",
    "    Splits input items into parts based on size constraints using recursion.\n",
    "    Returns a list of part dicts.\n",
    "    \"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    current_part = {\n",
    "        \"dirs\": [],\n",
    "        \"files\": [],\n",
    "        \"size\": 0\n",
    "    }\n",
    "    part_counter = 1\n",
    "    \n",
    "    def finalize_part(split_param=\"\"):\n",
    "        nonlocal part_counter, current_part\n",
    "        if current_part[\"dirs\"] or current_part[\"files\"]:\n",
    "            parts.append({\n",
    "                \"id\": part_counter,\n",
    "                \"part_dirs\": [i.to_dict() for i in current_part[\"dirs\"]],\n",
    "                \"part_files\": [i.to_dict() for i in current_part[\"files\"]],\n",
    "                \"total_size\": current_part[\"size\"],\n",
    "                \"split_param\": split_param, \n",
    "                \"done\": False\n",
    "            })\n",
    "            part_counter += 1\n",
    "            current_part = {\n",
    "                \"dirs\": [],\n",
    "                \"files\": [],\n",
    "                \"size\": 0\n",
    "            }\n",
    "\n",
    "    def process_items_recursive(items_list):\n",
    "        nonlocal current_part, part_counter\n",
    "        \n",
    "        for item in items_list:\n",
    "            # OPTIMIZATION: Use pre-calculated size if available\n",
    "            if item.size is not None:\n",
    "                size = item.size\n",
    "            else:\n",
    "                size = get_path_size(item.absolute_path)\n",
    "            \n",
    "            # 1. Check if item fits in the current part\n",
    "            if current_part[\"size\"] + size <= part_size_byte + max_overflow_byte:\n",
    "                if os.path.isdir(item.absolute_path):\n",
    "                    current_part[\"dirs\"].append(item)\n",
    "                else:\n",
    "                    current_part[\"files\"].append(item)\n",
    "                current_part[\"size\"] += size\n",
    "            \n",
    "            # 2. Item does NOT fit\n",
    "            else:\n",
    "                if os.path.isdir(item.absolute_path):\n",
    "                    # --- Recursion Step: Drill down into directory ---\n",
    "                    try:\n",
    "                        children = os.listdir(item.absolute_path)\n",
    "                        # We assume empty dirs (size 0) fit in step 1, so children list is not empty here.\n",
    "                        child_items = []\n",
    "                        for child in children:\n",
    "                            abs_p = os.path.join(item.absolute_path, child)\n",
    "                            rel_p = os.path.join(item.relative_path, child)\n",
    "                            # Ancestor stays same\n",
    "                            new_item = PathItem(abs_p, rel_p, item.ancestor)\n",
    "                            child_items.append(new_item)\n",
    "                        \n",
    "                        process_items_recursive(child_items)\n",
    "                            \n",
    "                    except PermissionError:\n",
    "                        print(f\"Skipping {item.absolute_path}: Permission denied.\")\n",
    "                \n",
    "                else:\n",
    "                    # File handling\n",
    "                    if size > part_size_byte + max_overflow_byte:\n",
    "                        finalize_part()\n",
    "                        # Add to its own part with split param\n",
    "                        # FIX: Format the bytes to compatible string (e.g. 100m)\n",
    "                        fmt_split = format_split_size(part_size_byte)\n",
    "                        parts.append({\n",
    "                            \"id\": part_counter,\n",
    "                            \"part_dirs\": [],\n",
    "                            \"part_files\": [item.to_dict()],\n",
    "                            \"total_size\": size,\n",
    "                            \"split_param\": fmt_split,\n",
    "                            \"done\": False\n",
    "                        })\n",
    "                        part_counter += 1\n",
    "                    else:\n",
    "                        finalize_part()\n",
    "                        current_part[\"files\"].append(item)\n",
    "                        current_part[\"size\"] += size\n",
    "\n",
    "    # Start the process\n",
    "    all_inputs = input_items[0] + input_items[1]\n",
    "    \n",
    "    sys.setrecursionlimit(max(2000, sys.getrecursionlimit()))\n",
    "    \n",
    "    process_items_recursive(all_inputs)\n",
    "    finalize_part() \n",
    "    \n",
    "    return parts\n",
    "\n",
    "def zip_part(input, saveto: str = \"\", part_size: str =\"20 GB\", max_overflow: str = \"1 GB\", process_file: str = \"\"):\n",
    "    \"\"\"\n",
    "    Splits zipping job into parts, persists state, and executes one part at a time.\n",
    "    \"\"\"\n",
    "    cwd = os.getcwd()\n",
    "    part_size_byte = str_num(part_size)\n",
    "    max_overflow_byte = str_num(max_overflow)\n",
    "    \n",
    "    input_list = input.split(\"|\")\n",
    "    raw_items = [] \n",
    "    input_hashes = []\n",
    "    \n",
    "    for path in input_list:\n",
    "        path = remove_quotes(path)\n",
    "        if os.path.exists(path):\n",
    "            size = get_path_size(path)\n",
    "            phash = get_path_hash(path, size)\n",
    "            raw_items.append({\"path\": path, \"size\": size, \"hash\": phash})\n",
    "            input_hashes.append(int(phash, 16))\n",
    "    \n",
    "    if not raw_items:\n",
    "        print(\"No valid input items found.\")\n",
    "        return\n",
    "\n",
    "    job_hash = calculate_combined_hash(input_hashes)\n",
    "    \n",
    "    if not process_file:\n",
    "        process_file = os.path.join(cwd, f\"zip-part-process-{job_hash}.json\")\n",
    "    \n",
    "    process_object = None\n",
    "    \n",
    "    if os.path.exists(process_file):\n",
    "        try:\n",
    "            with open(process_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                stored_hashes = data.get(\"input_hashes\", [])\n",
    "                current_hashes = [i[\"hash\"] for i in raw_items]\n",
    "                \n",
    "                if set(stored_hashes) == set(current_hashes):\n",
    "                    process_object = data\n",
    "                    print(f\"Resuming job from {process_file}\")\n",
    "                else:\n",
    "                    print(\"Existing process file hash mismatch. Discarding and starting fresh.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading process file: {e}\")\n",
    "    \n",
    "    if not process_object:\n",
    "        print(\"Calculating parts... this might take a moment.\")\n",
    "        \n",
    "        initial_path_items_dirs = []\n",
    "        initial_path_items_files = []\n",
    "        \n",
    "        for item in raw_items:\n",
    "            path = item[\"path\"]\n",
    "            abs_p = os.path.abspath(path)\n",
    "            ancestor = os.path.dirname(abs_p)\n",
    "            rel_p = os.path.basename(abs_p)\n",
    "            # Pass the pre-calculated size here to PathItem\n",
    "            p_item = PathItem(abs_p, rel_p, ancestor, size=item[\"size\"])\n",
    "            \n",
    "            if os.path.isdir(path):\n",
    "                initial_path_items_dirs.append(p_item)\n",
    "            else:\n",
    "                initial_path_items_files.append(p_item)\n",
    "                \n",
    "        parts = create_job_parts((initial_path_items_dirs, initial_path_items_files), \n",
    "                                 part_size_byte, max_overflow_byte)\n",
    "        \n",
    "        process_object = {\n",
    "            \"job_hash\": job_hash,\n",
    "            \"input_hashes\": [i[\"hash\"] for i in raw_items],\n",
    "            \"parts\": parts\n",
    "        }\n",
    "        \n",
    "        with open(process_file, 'w') as f:\n",
    "            json.dump(process_object, f, indent=2)\n",
    "            print(f\"Job initialized. Process saved to {process_file}\")\n",
    "\n",
    "    parts = process_object[\"parts\"]\n",
    "    current_part = None\n",
    "    \n",
    "    for part in parts:\n",
    "        if not part[\"done\"]:\n",
    "            current_part = part\n",
    "            break\n",
    "            \n",
    "    if not current_part:\n",
    "        print(\"All parts are completed!\")\n",
    "        return\n",
    "\n",
    "    print(f\"Processing Part {current_part['id']} / {len(parts)}\")\n",
    "    print(f\"Part Size: {current_part['total_size'] / (1024*1024):.2f} MB\")\n",
    "    \n",
    "    part_dirs = [PathItem.from_dict(d) for d in current_part[\"part_dirs\"]]\n",
    "    part_files = [PathItem.from_dict(f) for f in current_part[\"part_files\"]]\n",
    "    \n",
    "    # --- New Naming Logic with Padding ---\n",
    "    # Template: packed-files-part{n}-i{m}.zip\n",
    "    # n = part id (padded), m = number of packed items (files+dirs)\n",
    "    \n",
    "    total_parts = len(parts)\n",
    "    padding_width = len(str(total_parts))\n",
    "    # Pad with zeros (e.g. 001 for 3 digit total)\n",
    "    part_str = f\"{current_part['id']:0{padding_width}d}\"\n",
    "    \n",
    "    item_count = len(part_dirs) + len(part_files)\n",
    "    filename = f\"packed-files-part{part_str}-i{item_count}.zip\"\n",
    "    \n",
    "    if saveto:\n",
    "        # If user provided a path, we use its directory but enforce our naming convention\n",
    "        if saveto.endswith(\".zip\"):\n",
    "            target_dir = os.path.dirname(saveto)\n",
    "        else:\n",
    "            target_dir = saveto\n",
    "            \n",
    "        part_saveto = os.path.join(target_dir, filename)\n",
    "    else:\n",
    "        part_saveto = filename\n",
    "\n",
    "    split_arg = current_part.get(\"split_param\", \"\")\n",
    "    \n",
    "    result_path = zip(\n",
    "        input_items=(part_dirs, part_files),\n",
    "        saveto=part_saveto,\n",
    "        split=split_arg,\n",
    "        size_limit=\"\", \n",
    "        deletefiles=False\n",
    "    )\n",
    "    \n",
    "    if result_path:\n",
    "        print(f\"Part {current_part['id']} Success: {result_path}\")\n",
    "        current_part[\"done\"] = True\n",
    "        \n",
    "        with open(process_file, 'w') as f:\n",
    "            json.dump(process_object, f, indent=2)\n",
    "    else:\n",
    "        print(f\"Part {current_part['id']} Failed.\")\n",
    "\n",
    "def unzip(input, save: str = \"\", callback = None):\n",
    "    save = save.strip()\n",
    "    if input:\n",
    "        print(f\"Unzipping: {input}\\nTo: {save}\")\n",
    "        saving = \"-d \" + f'\"{save}\"' if save else \"\"\n",
    "        !unzip \"$input\" $saving\n",
    "        print(f'Done, check output: {save}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Zip { form-width: \"2%\" }\n",
    "\n",
    "Input = \"\" #@param {type:\"string\"}\n",
    "SaveTo = \"\" #@param {type:\"string\"}\n",
    "Split = \"\" #@param {type:\"string\"}\n",
    "Op = \"Zip\" #@param [\"Zip\", \"Unzip\"] {type:\"raw\"}\n",
    "\n",
    "if Op == \"Zip\":\n",
    "        # !zip -r -q -j -9 $SaveTo $Input\n",
    "    zip_with_str_input(Input, SaveTo, split= Split)\n",
    "\n",
    "elif Op == \"Unzip\":\n",
    "    if os.path.exists(SaveTo):\n",
    "        print(\"File already exists!\")\n",
    "    else:\n",
    "        unzip(Input, SaveTo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Zip Parts { form-width: \"2%\" }\n",
    "\n",
    "Input = \"\" #@param {type:\"string\"}\n",
    "SaveTo = \"\" #@param {type:\"string\"}\n",
    "Part_Size = \"\" #@param {type:\"string\"}\n",
    "Max_Overflow = \"\" #@param {type:\"string\"}\n",
    "Process_File = \"\" #@param {type:\"string\"}\n",
    "Op = \"Zip\" #@param [\"Zip\", \"Unzip\"] {type:\"raw\"}\n",
    "\n",
    "if Op == \"Zip\":\n",
    "    if Part_Size:\n",
    "        if Max_Overflow:\n",
    "            zip_part(Input, SaveTo, part_size= Part_Size, max_overflow= Max_Overflow, process_file= Process_File)\n",
    "        else:\n",
    "            zip_part(Input, SaveTo, part_size= Part_Size, process_file= Process_File)\n",
    "    else:\n",
    "        zip_part(Input, SaveTo, process_file= Process_File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Download Files { form-width: \"2%\" }\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "zipFiles = glob.glob(\"*.z*\")\n",
    "zipFiles.sort()\n",
    "\n",
    "for f in zipFiles:\n",
    "    files.download(f)\n",
    "\n",
    "zipFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Delete Files { form-width: \"2%\" }\n",
    "\n",
    "for f in zipFiles:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Setup Rcl0ne with Config File{ form-width: \"2%\" }\n",
    " \n",
    "build_version = \"stable\" #@param [\"stable\", \"beta\"]\n",
    "automatically_clear_cell_output = True  # @param{type: \"boolean\"}\n",
    "# ================================================================ #\n",
    "\n",
    "import os\n",
    "import IPython\t\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "if build_version == \"stable\":\n",
    "\t!curl https://rclone.org/install.sh | sudo bash\n",
    "else:\n",
    "\t!curl https://rclone.org/install.sh | sudo bash -s beta\n",
    "\n",
    "!sudo apt-get -y install fuse3\n",
    "\n",
    "os.makedirs(\"/root/.config/rclone\", exist_ok=True)\n",
    "!mv \"/content/rclone.conf\" \"/root/.config/rclone\"\n",
    "\n",
    "if automatically_clear_cell_output is True:\n",
    "\tclear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Simple Rcl0ne{ form-width: \"2%\" }\n",
    "\n",
    "Source = \"\" #@param {type:\"string\"}\n",
    "Destination = \"\" #@param {type:\"string\"}\n",
    "Op = \"Move\" #@param [\"Copy\", \"Move\"] {type:\"string\"}\n",
    "\n",
    "if os.path.exists(Source):\n",
    "    basename = os.path.basename(Source)\n",
    "    op = \"copy\" if Op == \"Copy\" else \"move\"\n",
    "    cmd = f'rclone {op} -P --no-traverse \"{Source}\" drv2:\"{Destination}/{basename}\"'\n",
    "    !$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "t03ZdwQ-IvPv"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Cloud to Cloud Operations with Rcl0ne { form-width: \"2%\" }\n",
    "\n",
    "Mode = \"Copy\" #@param [\"Copy\", \"Move\", \"Sync\", \"Checker\", \"Deduplicate\", \"Remove Empty Directories\", \"Empty Trash\"]\n",
    "Source = \"\" #@param {type:\"string\"}\n",
    "Destination = \"\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown <b>Global Configuration</b>\n",
    "Extra_Arguments = \"\" #@param {type:\"string\"}\n",
    "Compare = \"Size & Mod-Time\" #@param [\"Size & Mod-Time\", \"Size & Checksum\", \"Only Mod-Time\", \"Only Size\", \"Only Checksum\"]\n",
    "Checkers = 5 #@param {type:\"slider\", min:1, max:40, step:1}\n",
    "Transfers = 5 #@param {type:\"slider\", min:1, max:20, step:1}\n",
    "Dry_Run = False #@param {type:\"boolean\"}\n",
    "Do_not_cross_filesystem_boundaries = False\n",
    "Do_not_update_modtime_if_files_are_identical = False #@param {type:\"boolean\"}\n",
    "Google_Drive_optimization = False #@param {type:\"boolean\"}\n",
    "Large_amount_of_files_optimization = False #@param {type:\"boolean\"}\n",
    "Simple_Ouput = True #@param {type:\"boolean\"}\n",
    "Skip_all_files_that_exist = False #@param {type:\"boolean\"}\n",
    "Skip_files_that_are_newer_on_the_destination = False #@param {type:\"boolean\"}\n",
    "Output_Log_File = \"OFF\" #@param [\"OFF\", \"NOTICE\", \"INFO\", \"ERROR\", \"DEBUG\"]\n",
    "\n",
    "#@markdown <br><b> Sync Configuration </b>\n",
    "Sync_Mode = \"Delete during transfer\" #@param [\"Delete during transfer\", \"Delete before transfering\", \"Delete after transfering\"]\n",
    "Track_Renames = False #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown <b>Deduplicate Configuration </b>\n",
    "Deduplicate_Mode = \"Interactive\" #@param [\"Interactive\", \"Skip\", \"First\", \"Newest\", \"Oldest\", \"Largest\", \"Rename\"]\n",
    "Deduplicate_Use_Trash = True #@param {type:\"boolean\"}\n",
    "\n",
    "#@markdown ---\n",
    "automatically_clear_cell_output = False  # @param{type: \"boolean\"}\n",
    "# ================================================================ #\n",
    "\n",
    "##### Importing the needed modules\n",
    "import os\n",
    "import IPython\n",
    "from IPython.display import  clear_output\n",
    "\n",
    "bufferC = \"--buffer-size 96M\"\n",
    "\n",
    "if Compare == \"Size & Checksum\":\n",
    "    compareC = \"-c\"\n",
    "elif Compare == \"Only Mod-Time\":\n",
    "    compareC = \"--ignore-size\"\n",
    "elif Compare == \"Only Size\":\n",
    "    compareC = \"--size-only\"\n",
    "elif Compare == \"Only Checksum\":\n",
    "    compareC = \"-c --ignore-size\"\n",
    "else:\n",
    "    compareC = \"\"\n",
    "\n",
    "sourceC = Source\n",
    "destinationC = Destination\n",
    "transfersC = \"--transfers \"+str(Transfers)\n",
    "checkersC = \"--checkers \"+str(Checkers)\n",
    "\n",
    "if Skip_files_that_are_newer_on_the_destination == True:\n",
    "    skipnewC = \"-u\"\n",
    "else:\n",
    "    skipnewC = \"\"\n",
    "  \n",
    "if Skip_all_files_that_exist == True:\n",
    "    skipexistC = \"--ignore-existing\"\n",
    "else:\n",
    "    skipexistC = \"\"\n",
    "  \n",
    "if Do_not_cross_filesystem_boundaries == True:\n",
    "    nocrossfilesystemC = \"--one-file-system\"\n",
    "else:\n",
    "    nocrossfilesystemC = \"\"\n",
    "  \n",
    "if Do_not_update_modtime_if_files_are_identical == True:\n",
    "    noupdatemodtimeC = \"--no-update-modtime\"\n",
    "else:\n",
    "    noupdatemodtimeC = \"\"\n",
    "\n",
    "if Large_amount_of_files_optimization == True:\n",
    "    filesoptimizeC = \"--fast-list\"\n",
    "else:\n",
    "    filesoptimizeC = \"\"\n",
    "  \n",
    "if Google_Drive_optimization == True:\n",
    "    driveoptimizeC = \"--drive-chunk-size 32M --drive-acknowledge-abuse --drive-keep-revision-forever\"\n",
    "else:\n",
    "    driveoptimizeC = \"\"\n",
    "  \n",
    "if Dry_Run == True:\n",
    "    dryrunC = \"-n\"\n",
    "else:\n",
    "    dryrunC = \"\"\n",
    "  \n",
    "if Output_Log_File != \"OFF\":\n",
    "    statsC = \"--log-file=/root/.rclone_log/rclone_log.txt\"\n",
    "else:\n",
    "    if Simple_Ouput == True:\n",
    "        statsC = \"-v --stats-one-line --stats=5s\"\n",
    "    else:\n",
    "        statsC = \"-v --stats=5s\"\n",
    "statsC = \"\"\n",
    "\n",
    "if Output_Log_File == \"INFO\":\n",
    "    loglevelC = \"--log-level INFO\"\n",
    "elif Output_Log_File == \"ERROR\":\n",
    "    loglevelC = \"--log-level ERROR\"\n",
    "elif Output_Log_File == \"DEBUG\":\n",
    "    loglevelC = \"--log-level DEBUG\"\n",
    "else:\n",
    "    loglevelC = \"\"\n",
    "\n",
    "extraC = Extra_Arguments\n",
    "\n",
    "if Sync_Mode == \"Delete during transfer\":\n",
    "    syncmodeC = \"--delete-during\"\n",
    "elif Sync_Mode == \"Delete before transfering\":\n",
    "    syncmodeC = \"--delete-before\"\n",
    "elif Sync_Mode == \"Delete after transfering\":\n",
    "    syncmodeC = \"--delete-after\"\n",
    "  \n",
    "if Track_Renames == True:\n",
    "    trackrenamesC = \"--track-renames\"\n",
    "else:\n",
    "    trackrenamesC = \"\"\n",
    "  \n",
    "if Deduplicate_Mode == \"Interactive\":\n",
    "    deduplicateC = \"interactive\"\n",
    "elif Deduplicate_Mode == \"Skip\":\n",
    "    deduplicateC = \"skip\"\n",
    "elif Deduplicate_Mode == \"First\":\n",
    "    deduplicateC = \"first\"\n",
    "elif Deduplicate_Mode == \"Newest\":\n",
    "    deduplicateC = \"newest\"\n",
    "elif Deduplicate_Mode == \"Oldest\":\n",
    "    deduplicateC = \"oldest\"\n",
    "elif Deduplicate_Mode == \"Largest\":\n",
    "    deduplicateC = \"largest\"\n",
    "elif Deduplicate_Mode == \"Rename\":\n",
    "    deduplicateC = \"rename\"\n",
    "  \n",
    "if Deduplicate_Use_Trash == True:\n",
    "    deduplicatetrashC = \"\"\n",
    "else:\n",
    "    deduplicatetrashC = \"--drive-use-trash=false\"\n",
    "\n",
    "##### rclone Execution\n",
    "if Output_Log_File != \"OFF\" and Mode != \"Config\":\n",
    "    !mkdir -p -m 666 /root/.rclone_log/\n",
    "    print(\"Logging enabled\")\n",
    "\n",
    "if Mode == \"Copy\":\n",
    "    !rclone --config=/root/.config/rclone/rclone.conf copy \"$sourceC\" \"$destinationC\" $transfersC $checkersC $statsC $loglevelC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
    "elif Mode == \"Move\":\n",
    "    !rclone --config=/root/.config/rclone/rclone.conf move \"$sourceC\" \"$destinationC\" $transfersC $checkersC $statsC $loglevelC --delete-empty-src-dirs $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
    "elif Mode == \"Sync\":\n",
    "    !rclone --config=/root/.config/rclone/rclone.conf sync \"$sourceC\" \"$destinationC\" $transfersC $checkersC $statsC $loglevelC $syncmodeC $trackrenamesC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
    "elif Mode == \"Checker\":\n",
    "    !rclone --config=/root/.config/rclone/rclone.conf check \"$sourceC\" \"$destinationC\" $checkersC $statsC $loglevelC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
    "elif Mode == \"Deduplicate\":\n",
    "    !rclone --config=/root/.config/rclone/rclone.conf dedupe \"$sourceC\" $checkersC $statsC $loglevelC --dedupe-mode $deduplicateC $deduplicatetrashC $compareC $skipnewC $skipexistC $nocrossfilesystemC $noupdatemodtimeC $bufferC $filesoptimizeC $driveoptimizeC $dryrunC $extraC\n",
    "elif Mode == \"Remove Empty Directories\":\n",
    "    !rclone --config=/root/.config/rclone/rclone.conf rmdirs \"$sourceC\" $statsC $loglevelC $dryrunC $extraC\n",
    "elif Mode == \"Empty Trash\":\n",
    "    !rclone --config=/root/.config/rclone/rclone.conf cleanup \"$sourceC\" $statsC $loglevelC $dryrunC $extraC\n",
    "\n",
    "##### Log Output\n",
    "if Output_Log_File != \"OFF\" and Mode != \"Config\":\n",
    "\n",
    "    ##### Rename log file and output settings.\n",
    "    !mv /root/.rclone_log/rclone_log.txt /root/.rclone_log/rclone_log_$(date +%Y-%m-%d_%H.%M.%S).txt\n",
    "    with open(\"/root/.rclone_log/\" + Mode + \"_settings.txt\", \"w\") as f:\n",
    "        f.write(\"Mode: \" + Mode + \\\n",
    "            \"\\nCompare: \" + Compare + \\\n",
    "            \"\\nSource: \\\"\" + Source + \\\n",
    "            \"\\\"\\nDestination: \\\"\" + Destination + \\\n",
    "            \"\\\"\\nTransfers: \" + str(Transfers) + \\\n",
    "            \"\\nCheckers: \" + str(Checkers) + \\\n",
    "            \"\\nSkip files that are newer on the destination: \" + str(Skip_files_that_are_newer_on_the_destination) + \\\n",
    "            \"\\nSkip all files that exist: \" + str(Skip_all_files_that_exist) + \\\n",
    "            \"\\nDo not cross filesystem boundaries: \" + str(Do_not_cross_filesystem_boundaries) + \\\n",
    "            \"\\nDo not update modtime if files are identical: \" + str(Do_not_update_modtime_if_files_are_identical) + \\\n",
    "            \"\\nDry-Run: \" + str(Dry_Run) + \\\n",
    "            \"\\nOutput Log Level: \" + Output_Log_File + \\\n",
    "            \"\\nExtra Arguments: \\\"\" + Extra_Arguments + \\\n",
    "            \"\\\"\\nSync Moden: \" + Sync_Mode + \\\n",
    "            \"\\nTrack Renames: \" + str(Track_Renames) + \\\n",
    "            \"\\nDeduplicate Mode: \" + Deduplicate_Mode + \\\n",
    "            \"\\nDeduplicate Use Trash: \" + str(Deduplicate_Use_Trash))\n",
    "\n",
    "    ##### Compressing log file.\n",
    "    !rm -f /root/rclone_log.zip\n",
    "    !zip -r -q -j -9 /root/rclone_log.zip /root/.rclone_log/\n",
    "    !rm -rf /root/.rclone_log/\n",
    "    !mkdir -p -m 666 /root/.rclone_log/\n",
    "\n",
    "    ##### Send Log\n",
    "    if os.path.isfile(\"/root/rclone_log.zip\") == True:\n",
    "        try:\n",
    "            files.download(\"/root/rclone_log.zip\")\n",
    "            !rm -f /root/rclone_log.zip\n",
    "            print(\"Sending log to your browser...\")\n",
    "        except:\n",
    "            !mv /root/rclone_log.zip /content/rclone_log_$(date +%Y-%m-%d_%H.%M.%S).zip\n",
    "            print(\"You can use file explorer to download the log file\")\n",
    "    else:\n",
    "        clear_output()\n",
    "        print(\"There is no log file\")\n",
    "\n",
    "### Operation has been successfully completed.\n",
    "if Mode != \"Config\":\n",
    "    print(\"Operation has been successfully completed\")\n",
    "\n",
    "##### Automatically clear terminal output if the checkbox's value on the top is set to True.\n",
    "if automatically_clear_cell_output is True:\n",
    "    clear_output()\n",
    "else:\n",
    "\tpass##### Automatically clear terminal output if the checkbox's value on the top is set to True.\n",
    "if automatically_clear_cell_output is True:\n",
    "    clear_output()\n",
    "else:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Rcl0ne WebUI Configuration {form-width: \"2%\"}\n",
    "#@markdown rclone WebUI Default Credential\n",
    "#@markdown >Username: user</br>Password: pass\n",
    "\n",
    "USE_FREE_TOKEN = True\n",
    "TOKEN = \"\"\n",
    "REGION = \"US\"\n",
    "Tunneling = \"argo_tunnel_(cloudflare)\" #@param [\"argo_tunnel_(cloudflare)\", \"localhost.run\", \"ngrok\"]\n",
    "\n",
    "if Tunneling == \"argo_tunnel_(cloudflare)\":\n",
    "    PORT_FORWARD = \"argotunnel\"\n",
    "elif Tunneling == \"localhost.run\":\n",
    "    PORT_FORWARD = \"localhost\"\n",
    "elif Tunneling == \"ngrok\":\n",
    "    PORT_FORWARD = \"ngrok\"\n",
    "# ================================================================ #\n",
    "\n",
    "import os, signal, random, string, urllib.request, time\n",
    "from IPython.display import HTML, clear_output\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "runW = get_ipython()\n",
    "\n",
    "if not os.path.exists(\"/root/.ipython/mixlab.py\"):\n",
    "    from shlex import split as _spl\n",
    "    from subprocess import run\n",
    "\n",
    "    shellCmd = \"wget -qq https://shirooo39.github.io/MiXLab/resources/mixlab.py \\\n",
    "                -O /root/.ipython/mixlab.py\"\n",
    "    run(_spl(shellCmd))\n",
    "\n",
    "from mixlab import (\n",
    "    runSh,\n",
    "    loadingAn,\n",
    "    PortForward_wrapper,\n",
    "    displayUrl,\n",
    "    findProcess,\n",
    "    CWD,\n",
    "    textAn,\n",
    "    checkAvailable,\n",
    "    displayOutput,\n",
    "    prepareSession,\n",
    "    rcloneConfigurationPath,\n",
    "    accessSettingFile,\n",
    "    memGiB\n",
    ")\n",
    "\n",
    "loadingAn()\n",
    "prepareSession()\n",
    "\n",
    "pid = findProcess(\"rclone\", \"rcd\", isPid=True)\n",
    "\n",
    "try:\n",
    "    os.kill(int(pid), signal.SIGTERM)\n",
    "except TypeError:\n",
    "    pass\n",
    "  \n",
    "cmd = \"rclone rcd --rc-web-gui --rc-addr :5572\" \\\n",
    "      \" --rc-serve\" \\\n",
    "      \" --rc-user=user --rc-pass=pass\" \\\n",
    "      \" --rc-no-auth\" \\\n",
    "      rf\" --config {rcloneConfigurationPath}/rclone.conf\" \\\n",
    "      ' --user-agent \"Mozilla\"' \\\n",
    "      ' --transfers 16' \\\n",
    "      \" &\"\n",
    "\n",
    "runSh(cmd, shell=True)\n",
    "Server = PortForward_wrapper(PORT_FORWARD, TOKEN, USE_FREE_TOKEN, [['rcloneWebUI', 5572, 'http']], 'REGION.lower', [f\"{HOME}/.ngrok2/rcloneWebUI.yml\", 4099]).start('rcloneWebUI', displayB=False)\n",
    "clear_output()\n",
    "displayUrl(Server, pNamU='rclone WebUI : ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Rcl0ne CLI Configuration{ form-width: \"2%\" }\n",
    "# @markdown > After you have created a configuration, download the configuration file.</br>In the next time you want to mount an rclone drive, simply import the configuration file.\n",
    "USE_FREE_TOKEN = True\n",
    "TOKEN = \"\"  #\n",
    "REGION = \"US\"\n",
    "Tunneling = \"argo_tunnel_(cloudflare)\" #@param [\"argo_tunnel_(cloudflare)\", \"localhost.run\", \"ngrok\"]\n",
    "\n",
    "automatically_clear_cell_output = True  # @param{type: \"boolean\"}\n",
    "\n",
    "if Tunneling == \"argo_tunnel_(cloudflare)\":\n",
    "    PORT_FORWARD = \"argotunnel\"\n",
    "elif Tunneling == \"localhost.run\":\n",
    "    PORT_FORWARD = \"localhost\"\n",
    "elif Tunneling == \"ngrok\":\n",
    "    PORT_FORWARD = \"ngrok\"\n",
    "# ================================================================ #\n",
    "\n",
    "import os, urllib.request, IPython\n",
    "from IPython.display import HTML, clear_output\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "runW = get_ipython()\n",
    "\n",
    "if not os.path.exists(\"/root/.ipython/mixlab.py\"):\n",
    "  from shlex import split as _spl\n",
    "  from subprocess import run\n",
    "\n",
    "  shellCmd = \"wget -qq https://shirooo39.github.io/MiXLab/resources/mixlab.py \\\n",
    "                  -O /root/.ipython/mixlab.py\"\n",
    "  run(_spl(shellCmd))\n",
    "\n",
    "from mixlab import (\n",
    "    prepareSession,\n",
    "    rcloneConfigurationPath,\n",
    "    runSh,\n",
    "    PortForward_wrapper\n",
    ")\n",
    "\n",
    "import codecs, contextlib, locale, os, pty, select, signal, subprocess, sys, termios, time\n",
    "from IPython.utils import text\n",
    "import six\n",
    "from google.colab import _ipython\n",
    "from google.colab import _message\n",
    "from google.colab.output import _tags\n",
    "\n",
    "# Linux read(2) limits to 0x7ffff000 so stay under that for clarity.\n",
    "_PTY_READ_MAX_BYTES_FOR_TEST = 2**20  # 1MB\n",
    "\n",
    "_ENCODING = 'UTF-8'\n",
    "\n",
    "class ShellResult(object):\n",
    "  \"\"\"Result of an invocation of the shell magic.\n",
    "\n",
    "  Note: This is intended to mimic subprocess.CompletedProcess, but has slightly\n",
    "  different characteristics, including:\n",
    "    * CompletedProcess has separate stdout/stderr properties. A ShellResult\n",
    "      has a single property containing the merged stdout/stderr stream,\n",
    "      providing compatibility with the existing \"!\" shell magic (which this is\n",
    "      intended to provide an alternative to).\n",
    "    * A custom __repr__ method that returns output. When the magic is invoked as\n",
    "      the only statement in the cell, Python prints the string representation by\n",
    "      default. The existing \"!\" shell magic also returns output.\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, args, returncode, command_output):\n",
    "    self.args = args\n",
    "    self.returncode = returncode\n",
    "    self.output = command_output\n",
    "\n",
    "  def check_returncode(self):\n",
    "    if self.returncode:\n",
    "      raise subprocess.CalledProcessError(\n",
    "          returncode=self.returncode, cmd=self.args, output=self.output)\n",
    "\n",
    "  def _repr_pretty_(self, p, cycle):  # pylint:disable=unused-argument\n",
    "    # Note: When invoking the magic and not assigning the result\n",
    "    # (e.g. %shell echo \"foo\"), Python's default semantics will be used and\n",
    "    # print the string representation of the object. By default, this will\n",
    "    # display the __repr__ of ShellResult. Suppress this representation since\n",
    "    # the output of the command has already been displayed to the output window.\n",
    "    if cycle:\n",
    "      raise NotImplementedError\n",
    "\n",
    "\n",
    "def _configure_term_settings(pty_fd):\n",
    "  term_settings = termios.tcgetattr(pty_fd)\n",
    "  # ONLCR transforms NL to CR-NL, which is undesirable. Ensure this is disabled.\n",
    "  # http://man7.org/linux/man-pages/man3/termios.3.html\n",
    "  term_settings[1] &= ~termios.ONLCR\n",
    "\n",
    "  # ECHOCTL echoes control characters, which is undesirable.\n",
    "  term_settings[3] &= ~termios.ECHOCTL\n",
    "\n",
    "  termios.tcsetattr(pty_fd, termios.TCSANOW, term_settings)\n",
    "\n",
    "\n",
    "def _run_command(cmd, clear_streamed_output):\n",
    "  \"\"\"Calls the shell command, forwarding input received on the stdin_socket.\"\"\"\n",
    "  locale_encoding = locale.getpreferredencoding()\n",
    "  if locale_encoding != _ENCODING:\n",
    "    raise NotImplementedError(\n",
    "        'A UTF-8 locale is required. Got {}'.format(locale_encoding))\n",
    "\n",
    "  parent_pty, child_pty = pty.openpty()\n",
    "  _configure_term_settings(child_pty)\n",
    "\n",
    "  epoll = select.epoll()\n",
    "  epoll.register(\n",
    "      parent_pty,\n",
    "      (select.EPOLLIN | select.EPOLLOUT | select.EPOLLHUP | select.EPOLLERR))\n",
    "\n",
    "  try:\n",
    "    temporary_clearer = _tags.temporary if clear_streamed_output else _no_op\n",
    "\n",
    "    with temporary_clearer(), _display_stdin_widget(\n",
    "        delay_millis=500) as update_stdin_widget:\n",
    "      # TODO(b/115531839): Ensure that subprocesses are terminated upon\n",
    "      # interrupt.\n",
    "      p = subprocess.Popen(\n",
    "          cmd,\n",
    "          shell=True,\n",
    "          executable='/bin/bash',\n",
    "          stdout=child_pty,\n",
    "          stdin=child_pty,\n",
    "          stderr=child_pty,\n",
    "          close_fds=True)\n",
    "      # The child PTY is only needed by the spawned process.\n",
    "      os.close(child_pty)\n",
    "\n",
    "      return _monitor_process(parent_pty, epoll, p, cmd, update_stdin_widget)\n",
    "  finally:\n",
    "    epoll.close()\n",
    "    os.close(parent_pty)\n",
    "\n",
    "\n",
    "class _MonitorProcessState(object):\n",
    "\n",
    "  def __init__(self):\n",
    "    self.process_output = six.StringIO()\n",
    "    self.is_pty_still_connected = True\n",
    "\n",
    "\n",
    "def _monitor_process(parent_pty, epoll, p, cmd, update_stdin_widget):\n",
    "  \"\"\"Monitors the given subprocess until it terminates.\"\"\"\n",
    "  state = _MonitorProcessState()\n",
    "\n",
    "  # A single UTF-8 character can span multiple bytes. os.read returns bytes and\n",
    "  # could return a partial byte sequence for a UTF-8 character. Using an\n",
    "  # incremental decoder is incrementally fed input bytes and emits UTF-8\n",
    "  # characters.\n",
    "  decoder = codecs.getincrementaldecoder(_ENCODING)()\n",
    "\n",
    "  num_interrupts = 0\n",
    "  echo_status = None\n",
    "  while True:\n",
    "    try:\n",
    "      result = _poll_process(parent_pty, epoll, p, cmd, decoder, state)\n",
    "      if result is not None:\n",
    "        return result\n",
    "      term_settings = termios.tcgetattr(parent_pty)\n",
    "      new_echo_status = bool(term_settings[3] & termios.ECHO)\n",
    "      if echo_status != new_echo_status:\n",
    "        update_stdin_widget(new_echo_status)\n",
    "        echo_status = new_echo_status\n",
    "    except KeyboardInterrupt:\n",
    "      try:\n",
    "        num_interrupts += 1\n",
    "        if num_interrupts == 1:\n",
    "          p.send_signal(signal.SIGINT)\n",
    "        elif num_interrupts == 2:\n",
    "          # Process isn't responding to SIGINT and user requested another\n",
    "          # interrupt. Attempt to send SIGTERM followed by a SIGKILL if the\n",
    "          # process doesn't respond.\n",
    "          p.send_signal(signal.SIGTERM)\n",
    "          time.sleep(0.5)\n",
    "          if p.poll() is None:\n",
    "            p.send_signal(signal.SIGKILL)\n",
    "      except KeyboardInterrupt:\n",
    "        # Any interrupts that occur during shutdown should not propagate.\n",
    "        pass\n",
    "\n",
    "      if num_interrupts > 2:\n",
    "        # In practice, this shouldn't be possible since\n",
    "        # SIGKILL is quite effective.\n",
    "        raise\n",
    "\n",
    "\n",
    "def _poll_process(parent_pty, epoll, p, cmd, decoder, state):\n",
    "  \"\"\"Polls the process and captures / forwards input and output.\"\"\"\n",
    "\n",
    "  terminated = p.poll() is not None\n",
    "  if terminated:\n",
    "    termios.tcdrain(parent_pty)\n",
    "    # We're no longer interested in write events and only want to consume any\n",
    "    # remaining output from the terminated process. Continuing to watch write\n",
    "    # events may cause early termination of the loop if no output was\n",
    "    # available but the pty was ready for writing.\n",
    "    epoll.modify(parent_pty,\n",
    "                 (select.EPOLLIN | select.EPOLLHUP | select.EPOLLERR))\n",
    "\n",
    "  output_available = False\n",
    "\n",
    "  events = epoll.poll()\n",
    "  input_events = []\n",
    "  for _, event in events:\n",
    "    if event & select.EPOLLIN:\n",
    "      output_available = True\n",
    "      raw_contents = os.read(parent_pty, _PTY_READ_MAX_BYTES_FOR_TEST)\n",
    "      import re\n",
    "      decoded_contents = re.sub(r\"http:\\/\\/127.0.0.1:53682\", Server[\"url\"], \n",
    "                                decoder.decode(raw_contents))\n",
    "      sys.stdout.write(decoded_contents)\n",
    "      state.process_output.write(decoded_contents)\n",
    "\n",
    "    if event & select.EPOLLOUT:\n",
    "      # Queue polling for inputs behind processing output events.\n",
    "      input_events.append(event)\n",
    "\n",
    "    # PTY was disconnected or encountered a connection error. In either case,\n",
    "    # no new output should be made available.\n",
    "    if (event & select.EPOLLHUP) or (event & select.EPOLLERR):\n",
    "      state.is_pty_still_connected = False\n",
    "\n",
    "  for event in input_events:\n",
    "    # Check to see if there is any input on the stdin socket.\n",
    "    # pylint: disable=protected-access\n",
    "    input_line = _message._read_stdin_message()\n",
    "    # pylint: enable=protected-access\n",
    "    if input_line is not None:\n",
    "      # If a very large input or sequence of inputs is available, it's\n",
    "      # possible that the PTY buffer could be filled and this write call\n",
    "      # would block. To work around this, non-blocking writes and keeping\n",
    "      # a list of to-be-written inputs could be used. Empirically, the\n",
    "      # buffer limit is ~12K, which shouldn't be a problem in most\n",
    "      # scenarios. As such, optimizing for simplicity.\n",
    "      input_bytes = bytes(input_line.encode(_ENCODING))\n",
    "      os.write(parent_pty, input_bytes)\n",
    "\n",
    "  # Once the process is terminated, there still may be output to be read from\n",
    "  # the PTY. Wait until the PTY has been disconnected and no more data is\n",
    "  # available for read. Simply waiting for disconnect may be insufficient if\n",
    "  # there is more data made available on the PTY than we consume in a single\n",
    "  # read call.\n",
    "  if terminated and not state.is_pty_still_connected and not output_available:\n",
    "    sys.stdout.flush()\n",
    "    command_output = state.process_output.getvalue()\n",
    "    return ShellResult(cmd, p.returncode, command_output)\n",
    "\n",
    "  if not output_available:\n",
    "    # The PTY is almost continuously available for reading input to provide\n",
    "    # to the underlying subprocess. This means that the polling loop could\n",
    "    # effectively become a tight loop and use a large amount of CPU. Add a\n",
    "    # slight delay to give resources back to the system while monitoring the\n",
    "    # process.\n",
    "    # Skip this delay if we read output in the previous loop so that a partial\n",
    "    # read doesn't unnecessarily sleep before reading more output.\n",
    "    # TODO(b/115527726): Rather than sleep, poll for incoming messages from\n",
    "    # the frontend in the same poll as for the output.\n",
    "    time.sleep(0.1)\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _display_stdin_widget(delay_millis=0):\n",
    "  \"\"\"Context manager that displays a stdin UI widget and hides it upon exit.\n",
    "\n",
    "  Args:\n",
    "    delay_millis: Duration (in milliseconds) to delay showing the widget within\n",
    "      the UI.\n",
    "\n",
    "  Yields:\n",
    "    A callback that can be invoked with a single argument indicating whether\n",
    "    echo is enabled.\n",
    "  \"\"\"\n",
    "  shell = _ipython.get_ipython()\n",
    "  display_args = ['cell_display_stdin', {'delayMillis': delay_millis}]\n",
    "  _message.blocking_request(*display_args, parent=shell.parent_header)\n",
    "\n",
    "  def echo_updater(new_echo_status):\n",
    "    # Note: Updating the echo status uses colab_request / colab_reply on the\n",
    "    # stdin socket. Input provided by the user also sends messages on this\n",
    "    # socket. If user input is provided while the blocking_request call is still\n",
    "    # waiting for a colab_reply, the input will be dropped per\n",
    "    # https://github.com/googlecolab/colabtools/blob/56e4dbec7c4fa09fad51b60feb5c786c69d688c6/google/colab/_message.py#L100.\n",
    "    update_args = ['cell_update_stdin', {'echo': new_echo_status}]\n",
    "    _message.blocking_request(*update_args, parent=shell.parent_header)\n",
    "\n",
    "  yield echo_updater\n",
    "\n",
    "  hide_args = ['cell_remove_stdin', {}]\n",
    "  _message.blocking_request(*hide_args, parent=shell.parent_header)\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def _no_op():\n",
    "  yield\n",
    "\n",
    "prepareSession()\n",
    "\n",
    "Server = PortForward_wrapper(PORT_FORWARD, TOKEN, USE_FREE_TOKEN, [['rcloneConfiguration', 53682, 'http']], 'REGION.lower', [f\"{HOME}/.ngrok2/rcloneConfiguration.yml\", 4074]).start('rcloneConfiguration', displayB=False, v=False)\n",
    "\n",
    "printData = \"\"\"\n",
    "Before finishing the configuration, you will be redirected to an address.\n",
    "Replace the address http://127.0.0.0:53682 with {}\"\"\".format(Server['url'])\n",
    "print(printData)\n",
    "display(HTML('</br>(Click <a href=\"https://raw.githubusercontent.com/tofuliang/Google-Colab-CloudTorrent/master/src/rclone_config_create.gif\" target=\"_blank\">here</a> to see how to do it)</br></br>'))\n",
    "print(f\"{Server['url']}\", end=\"\\n\\n\")\n",
    "_run_command(f\"rclone config --config {rcloneConfigurationPath}/rclone.conf\", False)\n",
    "\n",
    "\n",
    "if automatically_clear_cell_output is True:\n",
    "\tclear_output()\n",
    "else:\n",
    "\tpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Simple Rcl0ne Drive Mounting{ form-width: \"2%\" }\n",
    "# @markdown <font size=5>Simple Rcl0ne Drive Mounting</font>\n",
    "\n",
    "cmd = rf\"rclone mount drive1: /content/drive1\" \\\n",
    "      ' --user-agent \"Mozilla\"' \\\n",
    "      ' --buffer-size 256M' \\\n",
    "      ' --transfers 10' \\\n",
    "      ' --vfs-cache-mode full' \\\n",
    "      ' --vfs-cache-max-age 0h0m1s' \\\n",
    "      ' --vfs-cache-poll-interval 0m1s' \\\n",
    "      ' --allow-other' \\\n",
    "      ' --daemon'\n",
    "!$cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Mount/Unmount Rcl0ne Drive { form-width: \"2%\" }\n",
    "\n",
    "Cache_Directory = \"DISK\" #@param [\"RAM\", \"DISK\"]\n",
    "# ================================================================ #\n",
    "\n",
    "import os\n",
    "from IPython.display import HTML, clear_output\n",
    "import uuid\n",
    "import ipywidgets as widgets\n",
    "from google.colab import output\n",
    "import re\n",
    "\n",
    "if not os.path.exists(\"/root/.ipython/mixlab.py\"):\n",
    "  from shlex import split as _spl\n",
    "  from subprocess import run\n",
    "\n",
    "  shellCmd = \"wget -qq https://shirooo39.github.io/MiXLab/resources/mixlab.py \\\n",
    "                  -O /root/.ipython/mixlab.py\"\n",
    "  run(_spl(shellCmd))\n",
    "\n",
    "from mixlab import (\n",
    "    runSh,\n",
    "    prepareSession,\n",
    "    rcloneConfigurationPath,\n",
    ")\n",
    "\n",
    "class MakeButton(object):\n",
    "  def __init__(self, title, callback, style):\n",
    "    self._title = title\n",
    "    self._callback = callback\n",
    "    self._style = style\n",
    "  def _repr_html_(self):\n",
    "    callback_id = 'button-' + str(uuid.uuid4())\n",
    "    output.register_callback(callback_id, self._callback)\n",
    "    if self._style != \"\":\n",
    "      style_html = \"p-Widget jupyter-widgets jupyter-button widget-button mod-\" + self._style\n",
    "    else:\n",
    "      style_html = \"p-Widget jupyter-widgets jupyter-button widget-button\"\n",
    "    template = \"\"\"<button class=\"{style_html}\" id=\"{callback_id}\">{title}</button>\n",
    "        <script>\n",
    "          document.querySelector(\"#{callback_id}\").onclick = (e) => {{\n",
    "            google.colab.kernel.invokeFunction('{callback_id}', [], {{}})\n",
    "            e.preventDefault();\n",
    "          }};\n",
    "        </script>\"\"\"\n",
    "    html = template.format(title=self._title, callback_id=callback_id, style_html=style_html)\n",
    "    return html\n",
    "  \n",
    "def ShowAC():\n",
    "  clear_output(wait=True)\n",
    "  display(\n",
    "      widgets.HBox(\n",
    "          [widgets.VBox(\n",
    "              [widgets.HTML(\n",
    "                  '''<h3 style=\"font-family:Trebuchet MS;color:#4f8bd6;margin-top:0px;\">\n",
    "                  Available drive to mount/unmount:</h3>\n",
    "                  '''\n",
    "                  ),\n",
    "               mountNam]\n",
    "               )\n",
    "          ]\n",
    "          )\n",
    "      )\n",
    "  \n",
    "  display(HTML(\"<br>\"), MakeButton(\"Mount\", MountCMD, \"primary\"),\n",
    "          MakeButton(\"Unmount\", unmountCMD, \"danger\"))\n",
    "\n",
    "prepareSession()\n",
    "content = open(f\"{rcloneConfigurationPath}/rclone.conf\").read()\n",
    "avCon = re.findall(r\"^\\[(.+)\\]$\", content, re.M)\n",
    "mountNam = widgets.Dropdown(options=avCon)\n",
    "\n",
    "if Cache_Directory == 'RAM':\n",
    "  cache_path = '/dev/shm'\n",
    "elif Cache_Directory == 'DISK':\n",
    "  os.makedirs('/tmp', exist_ok=True)\n",
    "  cache_path = '/tmp'\n",
    "\n",
    "def MountCMD():\n",
    "    mPoint = f\"/content/drives/{mountNam.value}\"\n",
    "    os.makedirs(mPoint, exist_ok=True)\n",
    "    cmd = rf\"rclone mount {mountNam.value}: {mPoint}\" \\\n",
    "      rf\" --config {rcloneConfigurationPath}/rclone.conf\" \\\n",
    "      ' --user-agent \"Mozilla\"' \\\n",
    "      ' --buffer-size 256M' \\\n",
    "      ' --transfers 10' \\\n",
    "      ' --vfs-cache-mode full' \\\n",
    "      ' --vfs-cache-max-age 0h0m1s' \\\n",
    "      ' --vfs-cache-poll-interval 0m1s' \\\n",
    "      f' --cache-dir {cache_path}' \\\n",
    "      ' --allow-other' \\\n",
    "      ' --daemon'\n",
    "\n",
    "    if runSh(cmd, shell=True) == 0:\n",
    "      print(f\"The drive have been successfully mounted! - \\t{mPoint}\")\n",
    "    else:\n",
    "      print(f\"Failed to mount the drive! - \\t{mPoint}\")\n",
    "\n",
    "def unmountCMD():\n",
    "  mPoint = f\"/content/drives/{mountNam.value}\"\n",
    "  if os.system(f\"fusermount -uz {mPoint}\") == 0:\n",
    "    runSh(f\"rm -r {mPoint}\")\n",
    "    print(f\"The drive have been successfully unmounted! - \\t{mPoint}\")\n",
    "  else:\n",
    "    runSh(f\"fusermount -uz {mPoint}\", output=True)\n",
    "\n",
    "ShowAC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Upload Rcl0ne Configuration File { form-width: \"2%\" }\n",
    "\n",
    "MODE = \"RCONFIG\" # @param ['UTILS', 'RCONFIG', 'RCONFIG_append', \"GENERATELIST\"]\n",
    "REMOTE = \"mnc\" # @param {type:\"string\"}\n",
    "QUERY_PATTERN = \"\" # @param {type:\"string\"}\n",
    "# @markdown > <p><font size=2px>For those who are unable to upload local file: <a href=\"https://stackoverflow.com/a/58661947\">StackOverflow</a></font></p>\n",
    "# ================================================================ #\n",
    "\n",
    "from os import path as _p\n",
    "from IPython.display import HTML, clear_output\n",
    "\n",
    "if not _p.exists(\"/root/.ipython/mixlab.py\"):\n",
    "    from shlex import split as _spl\n",
    "    from subprocess import run  # nosec\n",
    "\n",
    "    shellCmd = \"wget -qq https://shirooo39.github.io/MiXLab/resources/mixlab.py \\\n",
    "                    -O /root/.ipython/mixlab.py\"\n",
    "    run(_spl(shellCmd))  # nosec\n",
    "\n",
    "import importlib, mixlab\n",
    "from google.colab import files  # pylint: disable=import-error #nosec\n",
    "from mixlab import checkAvailable, runSh, rcloneConfigurationPath, prepareSession\n",
    "\n",
    "\n",
    "def generateUploadList():\n",
    "    prepareSession()\n",
    "    if checkAvailable(\"/content/upload.txt\"):\n",
    "        runSh(\"rm -f upload.txt\")\n",
    "    runSh(\n",
    "        f\"rclone --config {rcloneConfigurationPath}/rclone.conf lsf {REMOTE}: --include '{QUERY_PATTERN}' --drive-shared-with-me --files-only --max-depth 1 > /content/upload.txt\",\n",
    "        shell=True,  # nosec\n",
    "    )\n",
    "\n",
    "\n",
    "def uploadLocalFiles():\n",
    "    prepareSession()\n",
    "    if MODE == \"UTILS\":\n",
    "        filePath = \"/root/.ipython/mixlab.py\"\n",
    "    elif MODE in (\"RCONFIG\", \"RCONFIG_append\"):\n",
    "        filePath = f\"{rcloneConfigurationPath}/rclone.conf\"\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "      if checkAvailable(filePath):\n",
    "        runSh(f\"rm -f {filePath}\")\n",
    "      display(HTML(\"<h2 style=\\\"font-family:Trebuchet MS;color:#4f8bd6;\\\">Upload rclone.conf from your local machine.</h2><br>\"))\n",
    "      uploadedFile = files.upload()\n",
    "      fileNameDictKeys = uploadedFile.keys()\n",
    "      fileNo = len(fileNameDictKeys)\n",
    "      if fileNo > 1:\n",
    "          for fn in fileNameDictKeys:\n",
    "              runSh(f'rm -f \"/content/{fn}\"')\n",
    "          return print(\"\\nOnly upload one configuration file!\")\n",
    "      elif fileNo == 0:\n",
    "          return print(\"\\nFile upload cancelled.\")\n",
    "      elif fileNo == 1:\n",
    "          for fn in fileNameDictKeys:\n",
    "              if checkAvailable(f\"/content/{fn}\"):\n",
    "                  if MODE == \"RCONFIG_append\":\n",
    "                    import urllib\n",
    "                    urllib.request.urlretrieve(\"https://shirooo39.github.io/MiXLab/resources/configurations/rclone/rclone.conf\",\n",
    "                                               \"/usr/local/sessionSettings/rclone.conf\")\n",
    "                    with open(f\"/content/{fn}\", 'r+') as r:\n",
    "                      new_data = r.read()\n",
    "                      runSh(f'rm -f \"/content/{fn}\"')\n",
    "                    with open(filePath, 'r+') as f:\n",
    "                      old_data = f.read()\n",
    "                      f.seek(0)\n",
    "                      f.truncate(0)\n",
    "                      f.write(old_data + new_data)\n",
    "                    print(\"\\nUpdate completed.\")\n",
    "                  else:\n",
    "                    runSh(f'mv -f \"/content/{fn}\" {filePath}')\n",
    "                    runSh(f\"chmod 666 {filePath}\")\n",
    "                    runSh(f'rm -f \"/content/{fn}\"')\n",
    "                    importlib.reload(mixlab)\n",
    "                    !rm /content/upload.txt\n",
    "                    clear_output()\n",
    "                    print(\"rclone.conf has been uploaded to Colab!\")\n",
    "              return\n",
    "      else:\n",
    "          print(\"\\nNo file is chosen!\")\n",
    "          return\n",
    "    except:\n",
    "      return print(\"\\nFailed to upload!\")\n",
    "\n",
    "\n",
    "if MODE == \"GENERATELIST\":\n",
    "    generateUploadList()\n",
    "else:\n",
    "    uploadLocalFiles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW2"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Download Rcl0ne Configuration File { form-width: \"2%\" }\n",
    "MODE = \"RCONFIG\" # @param ['UTILS', 'RCONFIG']\n",
    "# ================================================================ #\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from google.colab import files\n",
    "\n",
    "def downloadFile():\n",
    "  if MODE == \"UTILS\":\n",
    "      filePath = \"/root/.ipython/mixlab.py\"\n",
    "  elif MODE == \"RCONFIG\":\n",
    "      filePath = f\"{rcloneConfigurationPath}/rclone.conf\"\n",
    "  else:\n",
    "      pass\n",
    "  try:\n",
    "    files.download(filePath)\n",
    "  except FileNotFoundError:\n",
    "    print(\"File not found!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  downloadFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW5"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Obselete { form-width: \"2%\" }\n",
    "\n",
    "_path_inner_chars = '/\\\\:?*<>\\0|\"'\n",
    "_segment = f'[^{_path_inner_chars}]+'\n",
    "# Path pattern is enclosed in a raw f-string with re.VERBOSE for readability.\n",
    "_path = rf\"\"\"\n",
    "(?: / (?: {_segment} (?: / {_segment} )* )? /?\n",
    "|  (?: [^\\s~{_path_inner_chars}][^~{_path_inner_chars}]* ) (?: / {_segment} )* /? )\n",
    "\"\"\"\n",
    "linux_path_regex_str = rf\"(?:\\\"{_path}\\\"|'{_path}')|{_path}\"\n",
    "linuxfilepath_re = re.compile(linux_path_regex_str, re.VERBOSE)\n",
    "\n",
    "def str_num1(numstr):\n",
    "    num = digits_re.search(numstr)\n",
    "    if not num:\n",
    "        return 0\n",
    "    letters = lastletters_re.search(numstr)\n",
    "    num = num.group()\n",
    "    if letters:\n",
    "        letters = letters.group()\n",
    "        if letters.startswith(\"k\"):\n",
    "            return int(num) * 1000\n",
    "        elif letters.startswith(\"m\"):\n",
    "            return int(num) * 1000000\n",
    "        elif letters.startswith(\"g\"):\n",
    "            return int(num) * 1000000000\n",
    "    return int(num)\n",
    "\n",
    "\n",
    "def zip(input, saveto: str = \"\", split = \"\", size_limit= \"\", deletefiles= False, callback = None): \n",
    "    saveto = saveto.strip()\n",
    "    if input:\n",
    "        cwd = os.getcwd()\n",
    "        inputpathlist = linuxfilepath_re.findall(input)\n",
    "        size_limit = str_num(size_limit)\n",
    "        cm1, cm2 = \"\", \"\"\n",
    "        print(inputpathlist)\n",
    "        if saveto:  \n",
    "            sch = zipfile_re.search(saveto)\n",
    "            if sch:\n",
    "                savedir = os.path.dirname(saveto)\n",
    "                savename = saveto\n",
    "            else:\n",
    "                savedir = saveto\n",
    "                savename = os.path.join(saveto, savename) ## fix\n",
    "            if savedir:\n",
    "                os.makedirs(savedir, exist_ok=True)            \n",
    "        splitparam = f\" -s {split} \" if split else \"\"\n",
    "        if len(inputpathlist) == 1:\n",
    "            input = remove_quotes(input)\n",
    "            if size_limit and input.endswith(\"*\"):\n",
    "                inputpathlist = getwildcartpaths(input)\n",
    "            inputdir = os.path.dirname(input)\n",
    "            basename = os.path.basename(input)\n",
    "            savename = f\"{basename}.zip\"\n",
    "            input = f'\"{basename}\"'\n",
    "            if inputdir and os.path.isdir(inputdir):\n",
    "                os.chdir(inputdir)\n",
    "            preparam = \"-r\" if os.path.isdir(input) else \"-j\"\n",
    "            cm1 = f'zip -7 {preparam}{splitparam} -qdg \"{savename}\" {input}'\n",
    "        elif len(inputpathlist) > 1:\n",
    "            dirpaths, filepaths = organize_paths(inputpathlist)\n",
    "            savename = f\"zipped-files-{nowstr(True)}.zip\"\n",
    "            if dirpaths:\n",
    "                dirsstr = \" \".join(dirpaths)\n",
    "                cm1 = f'zip -7 -r{splitparam} -qdg \"{savename}\" {dirsstr}'\n",
    "            if filepaths:\n",
    "                filesstr = \" \".join(filepaths)\n",
    "                cm2 = f' && zip -7 -j{splitparam} -qdg \"{savename}\" {filesstr}'\n",
    "            if not cm1 and not cm2:\n",
    "                print(\"Input invalid.\")\n",
    "                return\n",
    "        else:\n",
    "            print(\"Empty input.\")\n",
    "            return\n",
    "        print(f\"Zipping: {input}\\nTo: {saveto}\")\n",
    "        cm = cm1 + cm2\n",
    "        print(cm)\n",
    "        !$cm\n",
    "        os.chdir(cwd)\n",
    "    else:\n",
    "        print(\"No input file or directory provided.\")\n",
    "\n",
    "\n",
    "def zip(input_items, saveto: str = \"\", split = \"\", size_limit= \"\", deletefiles= False, callback = None):\n",
    "    \"\"\"\n",
    "    Main zip function working with structured input_items.\n",
    "    \"\"\"\n",
    "    saveto = saveto.strip() if saveto else \"\"\n",
    "    cwd = os.getcwd()\n",
    "    \n",
    "    if not input_items or (not input_items[0] and not input_items[1]):\n",
    "        print(\"No input items provided.\")\n",
    "        return None\n",
    "\n",
    "    dirs_list_obj = input_items[0]\n",
    "    files_list_obj = input_items[1]\n",
    "    all_targets = dirs_list_obj + files_list_obj\n",
    "    \n",
    "    # --- Determine Default Filename ---\n",
    "    if len(all_targets) == 1:\n",
    "        path_for_name = all_targets[0].absolute_path\n",
    "        basename = os.path.basename(path_for_name)\n",
    "        default_savename = f\"{basename}.zip\"\n",
    "    else:\n",
    "        default_savename = f\"zipped-files-{nowstr(True)}.zip\"\n",
    "\n",
    "    # --- Process 'saveto' Logic ---\n",
    "    if saveto:\n",
    "        sch = zipfile_re.search(saveto)\n",
    "        if sch:\n",
    "            savename = saveto\n",
    "        else:\n",
    "            savename = os.path.join(saveto, default_savename)\n",
    "        \n",
    "        savedir = os.path.dirname(savename)\n",
    "        if savedir:\n",
    "            os.makedirs(savedir, exist_ok=True)\n",
    "    else:\n",
    "        savename = default_savename\n",
    "\n",
    "    # Convert savename to absolute path\n",
    "    savename = os.path.abspath(savename)\n",
    "\n",
    "    print(f\"To: {savename}\")\n",
    "    \n",
    "    splitparam = f\" -s {split} \" if split else \"\"\n",
    "    command_list = []\n",
    "\n",
    "    # --- Generate Commands ---\n",
    "    \n",
    "    # Process Directories\n",
    "    for item in dirs_list_obj:\n",
    "        ancestor = item.ancestor\n",
    "        rel_path = item.relative_path\n",
    "        cmd_chunk = f'cd \"{ancestor}\" && zip -7 -r{splitparam} -qdg \"{savename}\" \"{rel_path}\"'\n",
    "        command_list.append(cmd_chunk)\n",
    "        \n",
    "    # Process Files\n",
    "    for item in files_list_obj:\n",
    "        ancestor = item.ancestor\n",
    "        rel_path = item.relative_path\n",
    "        cmd_chunk = f'cd \"{ancestor}\" && zip -7{splitparam} -qdg \"{savename}\" \"{rel_path}\"'\n",
    "        command_list.append(cmd_chunk)\n",
    "\n",
    "    # --- Combine and Execute ---\n",
    "    \n",
    "    if not command_list:\n",
    "        print(\"No commands generated.\")\n",
    "        return None\n",
    "\n",
    "    cm = \" && \".join(command_list)\n",
    "    print(f\"Command: {cm}\")\n",
    "    \n",
    "    # Mock execution \n",
    "    # result = os.system(cm)\n",
    "    success = True \n",
    "    \n",
    "    # Restore original directory\n",
    "    os.chdir(cwd)\n",
    "    \n",
    "    if success:\n",
    "        return savename\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "ZqEu3vDTqnW5"
   },
   "outputs": [],
   "source": [
    "#@title &nbsp;&nbsp;&nbsp; Nothing{ form-width: \"2%\" }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
